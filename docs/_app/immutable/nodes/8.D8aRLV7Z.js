import{f as m,a as r}from"../chunks/knYbcFPT.js";import"../chunks/B1k9pQuk.js";import{M as i,R as u,K as f,S as v,$ as y,T as t,P as l,Q as o}from"../chunks/Bwovo2pA.js";import{h as b}from"../chunks/BgHiyIqd.js";import{s as n}from"../chunks/RnnW-mnZ.js";import{b as c}from"../chunks/BxPHKWaB.js";const B=!0,L=Object.freeze(Object.defineProperty({__proto__:null,prerender:B},Symbol.toStringTag,{value:"Module"}));var _=m('<meta name="description" content="Learn how to safely encode multi-gigabyte files to Base64 using chunked processing, FileReader streams, and memory-safe techniques."/> <meta property="og:title" content="Streaming Large Files to Base64 • AxelBase"/> <meta property="og:description" content="Avoid Out-of-Memory crashes when encoding huge files in the browser."/> <meta property="og:url"/> <meta property="og:type" content="article"/> <meta name="twitter:card" content="summary_large_image"/>',1),F=m(`<div class="container fade-in post-layout svelte-1li990r"><div class="breadcrumbs svelte-1li990r"><a class="svelte-1li990r">Blog</a> <span>/</span> <p>Streaming Large Files</p></div> <article class="prose svelte-1li990r"><h1 class="svelte-1li990r">Streaming Large Files to Base64 Without Crashing the Browser</h1> <p class="post-meta svelte-1li990r">Published: November 21, 2025</p> <p>One of the biggest pitfalls in client-side Base64 tools is attempting to read an entire large file (100 MB+) into memory at once — causing Out-of-Memory (OOM) crashes.</p> <h2 class="svelte-1li990r">The Correct Approach: Chunked Streaming</h2> <p>Use the FileReader API with <code>slice()</code> to process the file in small chunks (e.g. 1–5 MB):</p> <ul class="svelte-1li990r"><li>Read chunk → convert to Base64 → append to result</li> <li>Free memory with each iteration</li> <li>Update progress bar in real time</li> <li>Never exceed ~50 MB in memory</li></ul> <h2 class="svelte-1li990r">Why AxelBase Doesn't Crash</h2> <p>Our encoder uses <strong>streaming + requestAnimationFrame</strong> to yield control back to the browser, preventing freezes even on 1 GB+ files.</p> <h2 class="svelte-1li990r">FAQ</h2> <details class="svelte-1li990r"><summary class="svelte-1li990r">Can I use FileReader.readAsDataURL()?</summary> <p>Never for large files — it loads everything into memory at once.</p></details> <details class="svelte-1li990r"><summary class="svelte-1li990r">What about Web Workers?</summary> <p>Helpful, but not sufficient alone. You still need chunking.</p></details> <p class="italic-note svelte-1li990r">Large file support is a hallmark of professional web tools. Do it right — or don’t do it at all.</p></article></div>`);function x(p){var e=F();b("1li990r",g=>{var a=_(),h=u(f(a),6);t(4),i(()=>n(h,"content",`${c??""}/blog/posts/post5`)),v(()=>{y.title="Streaming Large Files to Base64 • AxelBase Guide"}),r(g,a)});var s=l(e),d=l(s);t(4),o(s),t(2),o(e),i(()=>n(d,"href",`${c??""}/blog`)),r(p,e)}export{x as component,L as universal};
