import{f as m,a as r}from"../chunks/hWZPI7nN.js";import"../chunks/DpboDwhz.js";import{$ as i,a3 as u,_ as f,a4 as v,a5 as y,a6 as t,a1 as l,a2 as o}from"../chunks/BdysBj66.js";import{h as b}from"../chunks/DpzxLHAf.js";import{s as n}from"../chunks/B_ZIPEiT.js";import{b as c}from"../chunks/BFvU-IR9.js";const B=!0,S=Object.freeze(Object.defineProperty({__proto__:null,prerender:B},Symbol.toStringTag,{value:"Module"}));var _=m('<meta name="description" content="Learn how to safely encode multi-gigabyte files to Base64 using chunked processing, FileReader streams, and memory-safe techniques."/> <meta property="og:title" content="Streaming Large Files to Base64 • AxelBase"/> <meta property="og:description" content="Avoid Out-of-Memory crashes when encoding huge files in the browser."/> <meta property="og:url"/> <meta property="og:type" content="article"/> <meta name="twitter:card" content="summary_large_image"/>',1),F=m(`<div class="container fade-in post-layout svelte-1li990r"><div class="breadcrumbs svelte-1li990r"><a class="svelte-1li990r">Blog</a> <span>/</span> <p>Streaming Large Files</p></div> <article class="prose svelte-1li990r"><h1 class="svelte-1li990r">Streaming Large Files to Base64 Without Crashing the Browser</h1> <p class="post-meta svelte-1li990r">Published: November 21, 2025</p> <p>One of the biggest pitfalls in client-side Base64 tools is attempting to read an entire large file (100 MB+) into memory at once — causing Out-of-Memory (OOM) crashes.</p> <h2 class="svelte-1li990r">The Correct Approach: Chunked Streaming</h2> <p>Use the FileReader API with <code>slice()</code> to process the file in small chunks (e.g. 1–5 MB):</p> <ul class="svelte-1li990r"><li>Read chunk → convert to Base64 → append to result</li> <li>Free memory with each iteration</li> <li>Update progress bar in real time</li> <li>Never exceed ~50 MB in memory</li></ul> <h2 class="svelte-1li990r">Why AxelBase Doesn't Crash</h2> <p>Our encoder uses <strong>streaming + requestAnimationFrame</strong> to yield control back to the browser, preventing freezes even on 1 GB+ files.</p> <h2 class="svelte-1li990r">FAQ</h2> <details class="svelte-1li990r"><summary class="svelte-1li990r">Can I use FileReader.readAsDataURL()?</summary> <p>Never for large files — it loads everything into memory at once.</p></details> <details class="svelte-1li990r"><summary class="svelte-1li990r">What about Web Workers?</summary> <p>Helpful, but not sufficient alone. You still need chunking.</p></details> <p class="italic-note svelte-1li990r">Large file support is a hallmark of professional web tools. Do it right — or don’t do it at all.</p></article></div>`);function x(p){var e=F();b("1li990r",g=>{var s=_(),h=u(f(s),6);t(4),i(()=>n(h,"content",`${c??""}/blog/posts/post5`)),v(()=>{y.title="Streaming Large Files to Base64 • AxelBase Guide"}),r(g,s)});var a=l(e),d=l(a);t(4),o(a),t(2),o(e),i(()=>n(d,"href",`${c??""}/blog`)),r(p,e)}export{x as component,S as universal};
